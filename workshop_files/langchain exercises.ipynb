{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Fundamentals & Agent Building\n",
    "## Student Workbook\n",
    "\n",
    "**Duration:** 45 minutes\n",
    "\n",
    "**What you will learn:**\n",
    "- What LangChain is and why it matters\n",
    "- How to build your first LLM-powered agent\n",
    "- Core concepts: Prompts, Tools, Agents\n",
    "- Portfolio-ready code you can show employers\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "- Follow along with the instructor's demonstrations\n",
    "- Run the code cells when instructed\n",
    "- Complete the exercises in the designated cells\n",
    "- Check the troubleshooting section at the bottom if you get stuck\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: What is LangChain?\n",
    "\n",
    "## The Problem LangChain Solves\n",
    "\n",
    "**Without LangChain:**\n",
    "- API calls are verbose\n",
    "- Memory management is manual\n",
    "- Error handling everywhere\n",
    "- Tool integration requires custom code\n",
    "- Result: 200+ lines of boilerplate for simple tasks\n",
    "\n",
    "**With LangChain:**\n",
    "- Simple LLM interface\n",
    "- Built-in memory\n",
    "- Error handling\n",
    "- Tool framework\n",
    "- Agent orchestration\n",
    "- Result: 5-10 lines of clean code\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚   Your App  â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚    LangChain        â”‚\n",
    "                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "                â”‚  â”‚ Prompts        â”‚ â”‚\n",
    "                â”‚  â”‚ Memory         â”‚ â”‚\n",
    "                â”‚  â”‚ Chains         â”‚ â”‚\n",
    "                â”‚  â”‚ Tools          â”‚ â”‚\n",
    "                â”‚  â”‚ Agents         â”‚ â”‚\n",
    "                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”Œâ”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”\n",
    "        â”‚OpenAI â”‚   â”‚ Anthropic  â”‚  â”‚ Google  â”‚\n",
    "        â”‚(GPT)  â”‚   â”‚ (Claude)   â”‚  â”‚(Gemini) â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Setup\n",
    "\n",
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETUP INSTRUCTIONS (Run these in your terminal FIRST)\n",
    "# ============================================\n",
    "\n",
    "# Step 1: Create a virtual environment\n",
    "# python -m venv venv\n",
    "\n",
    "# Step 2: Activate the virtual environment\n",
    "# Windows:   .\\venv\\Scripts\\Activate\n",
    "# Mac/Linux: source venv/bin/activate\n",
    "\n",
    "# Step 3: Install dependencies\n",
    "# pip install -r requirements.txt\n",
    "\n",
    "# Step 4: Select the venv as your Jupyter kernel (top-right in VS Code)\n",
    "\n",
    "# ============================================\n",
    "# Once setup is complete, you can skip this cell\n",
    "# The packages are already in requirements.txt\n",
    "# ============================================\n",
    "\n",
    "print(\"âœ“ If you've completed the setup steps above, you're ready to go!\")\n",
    "print(\"  - venv created and activated\")\n",
    "print(\"  - requirements.txt installed\")\n",
    "print(\"  - Kernel set to your venv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Your API Key\n",
    "\n",
    "**Option A: Using a .env file (recommended)**\n",
    "\n",
    "1. Create a file called `.env` in your project folder\n",
    "2. Add this line: `OPENAI_API_KEY=sk-your-key-here`\n",
    "3. Run the cell below\n",
    "\n",
    "**Option B: Direct entry (for this session only)**\n",
    "\n",
    "1. Uncomment the second option in the cell below\n",
    "2. Replace with your actual API key\n",
    "\n",
    "**Need an API key?** Go to https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP: Import libraries and load API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Option A: Load from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Option B: Set directly (uncomment and add your key)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-your-key-here\"\n",
    "\n",
    "# Check if key is loaded\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"âœ“ API key loaded successfully\")\n",
    "else:\n",
    "    print(\"âœ— API key not found - see troubleshooting section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Your First LLM Call\n",
    "\n",
    "## Demo: Watch the Instructor\n",
    "\n",
    "The instructor will show you how to:\n",
    "- Import the LLM\n",
    "- Create an instance\n",
    "- Send a prompt\n",
    "- Get a response\n",
    "\n",
    "**Follow along by running the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Simple LLM Call\n",
    "\n",
    "# Import the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create an instance\n",
    "# temperature=0.7 means: how creative (0=factual, 1=creative)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Send a prompt\n",
    "prompt = \"What is the best colour and why?\"\n",
    "\n",
    "# Get the response\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print it\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LLM RESPONSE:\")\n",
    "print(\"=\"*60)\n",
    "print(response.content) # Why do we use .content here? Change it and investigate.\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Meaning |\n",
    "|---------|----------|\n",
    "| **Model** | Which LLM to use (GPT-4, Claude, etc.) |\n",
    "| **Temperature** | Creativity level (0 = precise, 1 = random) |\n",
    "| **Prompt** | What you ask the LLM |\n",
    "| **Response** | What the LLM sends back |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Write Your Own Prompt\n",
    "\n",
    "**Instructions:**\n",
    "1. Replace the placeholder text with your own question\n",
    "2. Run the cell\n",
    "3. See what the LLM responds\n",
    "\n",
    "**Ideas for prompts:**\n",
    "- \"Why is Python better than JavaScript?\"\n",
    "- \"What's a cool fact about AI?\"\n",
    "- \"Tell me a funny joke about programming\"\n",
    "- \"What should I build as my first AI project?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your own prompt and get a response!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3.5: Output Parsers\n",
    "\n",
    "## Why Output Parsers Matter\n",
    "\n",
    "When you call an LLM, you get an `AIMessage` object back. Output parsers help you extract and structure the response.\n",
    "\n",
    "| Parser | Use Case | Output |\n",
    "|--------|----------|--------|\n",
    "| `StrOutputParser` | Get plain text | `str` |\n",
    "| `JsonOutputParser` | Get structured data | `dict` |\n",
    "\n",
    "**Run the cell below to see the difference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: StrOutputParser vs JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "# StrOutputParser - extracts plain text from AIMessage\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "response = llm.invoke(\"What is the capital of France? Reply in one word.\")\n",
    "text_only = str_parser.invoke(response)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"StrOutputParser Demo\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Raw response type: {type(response)}\")\n",
    "print(f\"Parsed text type:  {type(text_only)}\")\n",
    "print(f\"Parsed value: {text_only}\")\n",
    "\n",
    "# JsonOutputParser - for structured data\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"JsonOutputParser Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "response2 = llm.invoke(\"Return a JSON object with keys 'capital' and 'country' for France. Only return the JSON.\")\n",
    "parsed_json = json_parser.invoke(response2)\n",
    "\n",
    "print(f\"Parsed type: {type(parsed_json)}\")\n",
    "print(f\"Parsed value: {parsed_json}\")\n",
    "print(f\"Access 'capital': {parsed_json.get('capital', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3.6: Chains - The Heart of LangChain\n",
    "\n",
    "## Why \"LangChain\"?\n",
    "\n",
    "The name says it all: **Lang**uage model **Chain**ing.\n",
    "\n",
    "The core idea is simple but powerful: **connect components together using the pipe operator `|`**\n",
    "\n",
    "```\n",
    "Prompt  â†’  LLM  â†’  Parser  â†’  Output\n",
    "   |         |        |\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         CHAIN\n",
    "```\n",
    "\n",
    "**Without chains:**\n",
    "```python\n",
    "prompt = template.format(topic=\"AI\")\n",
    "response = llm.invoke(prompt)\n",
    "text = parser.invoke(response)\n",
    "```\n",
    "\n",
    "**With chains:**\n",
    "```python\n",
    "chain = template | llm | parser\n",
    "text = chain.invoke({\"topic\": \"AI\"})\n",
    "```\n",
    "\n",
    "Same result, cleaner code, easier to modify! <br>\n",
    "EXTENSION (if you're ahead): Why not incorporate some tools into the chain!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Building Chains with the Pipe Operator\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: Create a prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that explains topics simply.\"),\n",
    "    (\"user\", \"Explain {topic} in one sentence for a beginner.\")\n",
    "])\n",
    "\n",
    "# Step 2: Create the chain using | (pipe operator)\n",
    "# This is what LangChain is built for!\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Step 3: Run the chain - just pass in the variables\n",
    "print(\"=\" * 60)\n",
    "print(\"CHAIN DEMO: Prompt â†’ LLM â†’ Parser\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = chain.invoke({\"topic\": \"machine learning\"})\n",
    "print(f\"Topic: machine learning\")\n",
    "print(f\"Output: {result}\")\n",
    "\n",
    "# Try another topic - same chain, different input\n",
    "result2 = chain.invoke({\"topic\": \"neural networks\"})\n",
    "print(f\"\\nTopic: neural networks\")\n",
    "print(f\"Output: {result2}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Notice: One chain, multiple uses. This is the power of LangChain!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Chains Matter\n",
    "\n",
    "**Chains are composable** - swap any part without rewriting everything:\n",
    "\n",
    "```python\n",
    "# Change the model? Easy.\n",
    "chain = prompt | different_llm | parser\n",
    "\n",
    "# Change the output format? Easy.\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Add preprocessing? Easy.\n",
    "chain = preprocess | prompt | llm | parser\n",
    "```\n",
    "\n",
    "**From simple to complex:**\n",
    "\n",
    "| Complexity | Example |\n",
    "|------------|---------|\n",
    "| Simple | `prompt \\| llm \\| parser` |\n",
    "| Medium | `prompt \\| llm \\| parser \\| save_to_db` |\n",
    "| Advanced | **Agents** (chains that decide their own steps) |\n",
    "\n",
    "**Key insight:** Agents are just chains that can loop and make decisions about which tools to call next.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Building Your First Agent\n",
    "\n",
    "## What is an Agent?\n",
    "\n",
    "An agent is a **chain that can make decisions** and use **tools** to solve problems:\n",
    "- It **decides** which tool to use based on the question\n",
    "- It reads the tool result\n",
    "- It loops until the task is complete\n",
    "\n",
    "**Remember:** Chains flow in one direction (prompt â†’ llm â†’ output). Agents can loop and branch!\n",
    "\n",
    "```\n",
    "CHAIN:    prompt â†’ llm â†’ parser â†’ done\n",
    "\n",
    "AGENT:    prompt â†’ llm â†’ tool? â†’ observation â†’ llm â†’ tool? â†’ ... â†’ done\n",
    "                    â†‘__________________________|\n",
    "                           (loops until solved)\n",
    "```\n",
    "\n",
    "**Key difference:**\n",
    "- Without tools: LLM only knows what was in training data\n",
    "- With tools: LLM can access real-time data, compute, and more\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Define Tools\n",
    "\n",
    "A tool is a Python function that the agent can call.\n",
    "\n",
    "**Watch the instructor demonstrate, then run the cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# Tool 1: Search Wikipedia\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search Wikipedia for information about a topic.\n",
    "    Use this to find facts and background information.\n",
    "    \"\"\"\n",
    "    # Simulated response for demo purposes\n",
    "    return f\"Wikipedia results for '{query}': [Found detailed information about {query}]\"\n",
    "\n",
    "# TODO: Tool 2 - Calculator which evaluates simple math expressions (e.g. \"2 + 2\" or \"sqrt(16)\")\n",
    "\n",
    "\n",
    "print(\"âœ“ Tools defined:\")\n",
    "print(\"  - search_wikipedia\")\n",
    "print(\"  - calculate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the Agent\n",
    "\n",
    "Now we give these tools to the LLM and create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "# Define which tools the agent can use\n",
    "tools = [search_wikipedia]\n",
    "\n",
    "# Create the agent using LangGraph\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "print(\"âœ“ Agent created and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Agent\n",
    "\n",
    "Watch how the agent decides which tool to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent with a question\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AGENT DEMO: Calculate something and explain it\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [(\"user\", \"What is 15 * 12? Then search for what that number means.\")]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Just Happened?\n",
    "\n",
    "**Agent's thought process (from verbose output):**\n",
    "\n",
    "1. THOUGHT: \"User asked for 15*12 and then search for the result\"\n",
    "2. ACTION: Use 'calculate' tool with '15*12'\n",
    "3. OBSERVATION: \"Result: 15*12 = 180\"\n",
    "4. THOUGHT: \"Now I should search for 180\"\n",
    "5. ACTION: Use 'search_wikipedia' with '180'\n",
    "6. OBSERVATION: \"Wikipedia results for '180': [Found...]\"\n",
    "7. FINAL ANSWER: \"15*12 = 180. In history/math, 180 represents...\"\n",
    "\n",
    "**Key insight:** The agent DECIDED what to do. It wasn't programmed to search - it chose to!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Build Your Own Agent\n",
    "## Duration: 5-10 minutes\n",
    "\n",
    "### Challenge: Create Something Unique!\n",
    "\n",
    "Now it's YOUR turn. Don't just change the prompt â€” build something that solves a problem YOU care about.\n",
    "\n",
    "**Ideas for custom tools you could create:**\n",
    "\n",
    "| Tool Idea | What it does |\n",
    "|-----------|-------------|\n",
    "| `get_weather` | Returns weather for a city (simulated) |\n",
    "| `translate_text` | Translates text to another language |\n",
    "| `summarise_text` | Condenses long text into bullet points |\n",
    "| `get_stock_price` | Returns a stock price (simulated) |\n",
    "| `generate_password` | Creates a secure random password |\n",
    "| `convert_units` | Converts between units (km to miles, etc.) |\n",
    "\n",
    "**Or invent your own!** Think about:\n",
    "- What's a repetitive task you do often?\n",
    "- What information would be useful to look up?\n",
    "- What calculation or transformation would be helpful?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Build your own agent with custom tools!\n",
    "\n",
    "# Step 1: Create your own tool(s)\n",
    "# Copy this template and modify it:\n",
    "\n",
    "@tool\n",
    "def my_custom_tool(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Describe what your tool does here.\n",
    "    The agent reads this description to decide when to use it!\n",
    "    \"\"\"\n",
    "    # Your logic here - be creative!\n",
    "    return f\"Result for '{input_text}': [Your output here]\"\n",
    "\n",
    "# Example: A simple greeting tool\n",
    "@tool\n",
    "def get_greeting(name: str) -> str:\n",
    "    \"\"\"Generate a personalised greeting for someone.\"\"\"\n",
    "    return f\"Hello {name}! Welcome to the AI workshop. Hope you're having fun!\"\n",
    "\n",
    "\n",
    "# Step 2: Create an agent with YOUR tools\n",
    "my_tools = [my_custom_tool, get_greeting]  # Add your tools here\n",
    "my_agent = create_react_agent(llm, my_tools)\n",
    "\n",
    "\n",
    "# Step 3: Ask your agent a question that uses your tools\n",
    "result = my_agent.invoke({\n",
    "    \"messages\": [(\"user\", \"Greet someone called Alex and then use the custom tool on 'LangChain'\")]\n",
    "})\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"YOUR AGENT'S RESPONSE:\")\n",
    "print(\"=\"*70)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# CHALLENGE: Can you create a tool that does something genuinely useful?\n",
    "# Some of you will get to present it at the end if we have time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Recap\n",
    "\n",
    "## What You Learned\n",
    "\n",
    "**LangChain basics:**\n",
    "- What LangChain is and why it matters\n",
    "- How to import and use it\n",
    "\n",
    "**LLMs in Python:**\n",
    "- How to create an LLM instance\n",
    "- How to call it with a prompt\n",
    "- How to get and use the response\n",
    "\n",
    "**Output Parsers:**\n",
    "- How to extract clean text with `StrOutputParser`\n",
    "- How to get structured data with `JsonOutputParser`\n",
    "\n",
    "**Chains (the core concept!):**\n",
    "- How to use the pipe operator `|` to chain components\n",
    "- Why `prompt | llm | parser` is the foundation of LangChain\n",
    "- How chains make code reusable and composable\n",
    "\n",
    "**Tools:**\n",
    "- What tools are (functions the agent can call)\n",
    "- How to define tools with the @tool decorator\n",
    "- How tools give agents real-world capabilities\n",
    "\n",
    "**Agents:**\n",
    "- What agents are (chains with decision-making)\n",
    "- How agents decide which tools to use\n",
    "- How to create and run agents\n",
    "- How agents loop until tasks are complete\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "What your code can do:\n",
    "- Chat with documents (agent reads PDFs and answers questions)\n",
    "- Autonomous research (agent finds info from multiple sources)\n",
    "- Code debugging (agent analyses code and suggests fixes)\n",
    "- Data analysis (agent processes data and creates reports)\n",
    "- Customer service (agent handles customer questions with tools)\n",
    "- Task automation (agent decides what actions to take)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaway\n",
    "\n",
    "**You just built what AI engineers do daily.**\n",
    "\n",
    "- Companies like OpenAI, Anthropic, and Google use this exact pattern\n",
    "- This is day 2-3 work at a real AI startup\n",
    "- You have portfolio-ready code\n",
    "- Employers specifically look for this skill\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting & FAQ\n",
    "\n",
    "## API Key Issues\n",
    "\n",
    "**Problem: \"API key not found\"**\n",
    "\n",
    "Solutions:\n",
    "1. Make sure you created a `.env` file with `OPENAI_API_KEY=sk-...`\n",
    "2. Check the file is in your project root directory\n",
    "3. Restart your Jupyter kernel after creating the file\n",
    "\n",
    "**Problem: \"Invalid API key\"**\n",
    "\n",
    "Solutions:\n",
    "1. Go to https://platform.openai.com/api-keys\n",
    "2. Generate a new API key\n",
    "3. Copy the entire key (including sk- prefix)\n",
    "4. Paste it into your `.env` file\n",
    "\n",
    "---\n",
    "\n",
    "## LLM Call Issues\n",
    "\n",
    "**Problem: \"Rate limit exceeded\"**\n",
    "\n",
    "Solutions:\n",
    "1. You have made too many API calls\n",
    "2. Wait 1-2 minutes before trying again\n",
    "3. Use a cheaper model: `model=\"gpt-3.5-turbo\"`\n",
    "\n",
    "**Problem: \"Model not available\"**\n",
    "\n",
    "Solutions:\n",
    "1. Try a different model:\n",
    "   ```python\n",
    "   llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "   ```\n",
    "2. Check your OpenAI account has access to the model\n",
    "\n",
    "**Problem: \"Connection timeout\"**\n",
    "\n",
    "Solutions:\n",
    "1. Check your internet connection\n",
    "2. Try again in a few seconds\n",
    "3. Check OpenAI status page: https://status.openai.com/\n",
    "\n",
    "---\n",
    "\n",
    "## Agent Issues\n",
    "\n",
    "**Problem: Agent doesn't use tools**\n",
    "\n",
    "Solutions:\n",
    "1. Make your prompt more specific\n",
    "2. Add \"Use your tools to find facts\" to your prompt\n",
    "3. Check that tools are defined correctly\n",
    "\n",
    "**Problem: Agent keeps repeating itself**\n",
    "\n",
    "Solutions:\n",
    "1. Reduce temperature: `temperature=0.3` (more deterministic)\n",
    "2. Simplify your prompt\n",
    "3. Check tool outputs are helpful\n",
    "\n",
    "**Problem: Agent takes too long to run**\n",
    "\n",
    "Solutions:\n",
    "1. This is normal with multiple tool calls\n",
    "2. Try using fewer tools\n",
    "3. Use `gpt-3.5-turbo` instead of `gpt-4-turbo`\n",
    "\n",
    "**Problem: ImportError when importing from langchain**\n",
    "\n",
    "Solutions:\n",
    "1. Make sure you ran the installation cell first\n",
    "2. Restart your Jupyter kernel\n",
    "3. Check you typed the import statement correctly\n",
    "\n",
    "---\n",
    "\n",
    "## General Questions\n",
    "\n",
    "**Q: Why do I need temperature?**\n",
    "\n",
    "A: Temperature controls creativity. Use 0 for precise tasks (like agents), use 0.7+ for creative tasks.\n",
    "\n",
    "**Q: What does verbose=True do?**\n",
    "\n",
    "A: It shows you the agent's thinking process, so you can see which tools it used and why.\n",
    "\n",
    "**Q: How much does this cost?**\n",
    "\n",
    "A: OpenAI charges per token. Each demo call costs pennies. You get free trial credits.\n",
    "\n",
    "**Q: Can I use a different LLM?**\n",
    "\n",
    "A: Yes! LangChain works with Claude, Gemini, and others. Change the import and model accordingly.\n",
    "\n",
    "**Q: What's the difference between temperature 0.5 and 0.7?**\n",
    "\n",
    "A: 0.5 is more factual, 0.7 is more creative. There's no perfect number, experiment to find what works.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Assessment\n",
    "\n",
    "After this section, tick the boxes below if you can do each thing:\n",
    "\n",
    "## Understanding\n",
    "\n",
    "- [ ] I can explain what LangChain is\n",
    "- [ ] I understand why companies use it\n",
    "- [ ] I know what tools and agents are\n",
    "- [ ] I can explain how agents make decisions\n",
    "\n",
    "## Doing\n",
    "\n",
    "- [ ] I can install LangChain\n",
    "- [ ] I can create an LLM instance\n",
    "- [ ] I can call the LLM with a prompt\n",
    "- [ ] I can define custom tools\n",
    "- [ ] I can create an agent\n",
    "- [ ] I can run an agent and interpret output\n",
    "\n",
    "## Building\n",
    "\n",
    "- [ ] I can build an agent for my own use case\n",
    "- [ ] I can add custom tools\n",
    "- [ ] I can optimise prompts for better results\n",
    "\n",
    "## Challenge Questions\n",
    "\n",
    "Can you answer these?\n",
    "\n",
    "1. \"Can I explain what an agent is to someone else?\"\n",
    "2. \"Can I create a tool and add it to an agent?\"\n",
    "3. \"Can I write a prompt that makes an agent do what I want?\"\n",
    "4. \"Can I debug an agent that is not working?\"\n",
    "5. \"Can I think of a real problem I could solve with an agent?\"\n",
    "\n",
    "If you can answer YES to all 5, you have mastered this section! âœ…\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources for Learning More\n",
    "\n",
    "## Official Documentation\n",
    "\n",
    "- **LangChain Docs:** https://python.langchain.com/\n",
    "- **LangChain Agents:** https://python.langchain.com/docs/modules/agents/\n",
    "- **Tool Calling:** https://python.langchain.com/docs/modules/agents/tools/\n",
    "\n",
    "## Great Tutorials\n",
    "\n",
    "- LangChain Getting Started (quick intro to basics)\n",
    "- Build Your First Agent (step-by-step tutorial)\n",
    "- Advanced Tool Building (creating complex tools)\n",
    "\n",
    "## Practice Projects\n",
    "\n",
    "1. Email Assistant (agent reads emails and summarises)\n",
    "2. Code Helper (agent understands code and explains it)\n",
    "3. Research Bot (agent gathers info from multiple sources)\n",
    "4. Task Planner (agent creates and executes task plans)\n",
    "5. FAQ Answerer (agent finds answers in knowledge base)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Tips\n",
    "\n",
    "## Make Your Project Stand Out\n",
    "\n",
    "**On GitHub:**\n",
    "1. Create a clear README explaining what your agent does\n",
    "2. Include setup instructions so others can run it\n",
    "3. Show example outputs\n",
    "4. Explain your design choices\n",
    "5. Link to relevant job postings that need this skill\n",
    "\n",
    "**In interviews:**\n",
    "- Walk through your agent code\n",
    "- Explain why you chose specific tools\n",
    "- Discuss limitations and how to overcome them\n",
    "- Show how you debugged problems\n",
    "- Share what you would build next\n",
    "\n",
    "**Things that impress employers:**\n",
    "- Clean, documented code\n",
    "- Real-world problem solving\n",
    "- Multiple tools and agents\n",
    "- Error handling\n",
    "- Performance optimisation\n",
    "- Testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "\n",
    "## What You Accomplished Today\n",
    "\n",
    "You started knowing nothing about LangChain.\n",
    "\n",
    "You end knowing how to build AI agents.\n",
    "\n",
    "You have portfolio-ready code.\n",
    "\n",
    "You understand production-level concepts.\n",
    "\n",
    "---\n",
    "\n",
    "## The Real Opportunity\n",
    "\n",
    "This skill is in huge demand right now.\n",
    "\n",
    "**Job market:**\n",
    "- 80% of AI engineering jobs require this\n",
    "- Starting salary: GBP 50-70k\n",
    "- With 2 years experience: GBP 90-130k\n",
    "- Companies desperate to hire people who know this\n",
    "\n",
    "**What makes you valuable:**\n",
    "- Most people can use ChatGPT\n",
    "- You can BUILD AI SYSTEMS\n",
    "- You understand the architecture\n",
    "- You know production patterns\n",
    "- Employers want YOU\n",
    "\n",
    "---\n",
    "\n",
    "## One More Thing\n",
    "\n",
    "**The best way to learn:** Build something real.\n",
    "\n",
    "Do not just follow tutorials. Pick a problem YOU care about and solve it with an agent.\n",
    "\n",
    "**Ideas:**\n",
    "- Problem from your own life\n",
    "- Something that bothers you about your work\n",
    "- A tool you wish existed\n",
    "- An automation that would save time\n",
    "\n",
    "Build it. Deploy it. Show it off.\n",
    "\n",
    "**That is how you become an AI engineer.**\n",
    "\n",
    "---\n",
    "\n",
    "### Questions?\n",
    "\n",
    "If anything is unclear, now is the time to ask!\n",
    "\n",
    "The instructor is here to help. This is your foundation.\n",
    "\n",
    "Let us keep the energy high for what comes next! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
