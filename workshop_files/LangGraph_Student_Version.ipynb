{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph: Graph-Based LLM Orchestration\n",
        "**Duration:** 45 minutes\n",
        "**Learning Outcomes:**\n",
        "- Understand what LangGraph is and why use it\n",
        "- Build your first LLM graph\n",
        "- Learn core concepts: Prompts, Memory, Tools, Agents\n",
        "- Combine LangChain and LangGraph\n",
        "\n",
        "---\n",
        "\n",
        "## Section Overview\n",
        "\n",
        "| Start Time | Activity | Duration |\n",
        "|------|----------|----------|\n",
        "| 13:45 | Intro + Example | 7 mins |\n",
        "| 13:52 | Memory Demo | 5 mins |\n",
        "| 13:57 | Tool Demo | 8 mins |\n",
        "| 14:05 | Solo Exercise | 10 mins |\n",
        "| 14:15 | LAB: Multi-Agent Graph | 15 mins |\n",
        "\n",
        "*+ Time at the end*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üï∏Ô∏è What is LangGraph?\n",
        "\n",
        "LangGraph is a framework built on top of LangChain that enables developers to design stateful, multi-step, and multi-agent workflows using graph-based architectures.\n",
        "\n",
        "Instead of linear chains, LangGraph allows you to define:\n",
        "- **Nodes** ‚Üí steps, agents, or tool calls\n",
        "- **Edges** ‚Üí transitions between steps\n",
        "\n",
        "This enables more flexible, reliable, and production-ready AI systems.\n",
        "\n",
        "In this module, we explore how graph-based orchestration improves reasoning, tool usage, memory persistence, and multi-agent collaboration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ü§∑‚Äç‚ôÇÔ∏è Why Use LangGraph?\n",
        "\n",
        "LangGraph is ideal when applications require:\n",
        "\n",
        "- Long-running workflows\n",
        "- Memory persistence across steps\n",
        "- Tool invocation and dynamic decision-making\n",
        "- Multi-agent collaboration\n",
        "- Hybrid deterministic + agentic control\n",
        "\n",
        "It provides better state control, traceability, and reliability compared to traditional linear pipelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da86678",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üèóÔ∏è Graph Structure\n",
        "![alt text](image.png)\n",
        "\n",
        "---\n",
        "\n",
        "### üëãüåç Hello World Example (Learning Graphing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07995c13",
      "metadata": {},
      "source": [
        "We import our libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6def2807",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangGraph uses dictionaries, more accurately the class TypedDict, to model state\n",
        "# StateGraph is the class used to define the graph\n",
        "\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d77864",
      "metadata": {},
      "source": [
        "We define our Agent state and node functionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aff27205",
      "metadata": {},
      "outputs": [],
      "source": [
        "#You define a child class of TypedDict to be the state of your graph\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    message : str\n",
        "    name: str\n",
        "\n",
        "#Nodes are functions that take in state and return state\n",
        "def hello_world(state: AgentState) -> AgentState:\n",
        "    state['message'] = \"Hello \" + state['message']\n",
        "    return state\n",
        "\n",
        "def hello_name(state: AgentState) -> AgentState:\n",
        "    state['message'] = state['message'] + \", Hello \" + state['name']\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9f8bf59",
      "metadata": {},
      "source": [
        "We make the graph and compile it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0b4efdf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Here we define our graph\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "#Nodes have to be added before being linked\n",
        "graph.add_node(\"hello_node_1\", hello_world)\n",
        "graph.add_node(\"hello_node_2\", hello_name)\n",
        "\n",
        "graph.set_entry_point(\"hello_node_1\") # \"graph.add_edge(START, hello_node)\" also works (have to import START, END)\n",
        "graph.add_edge(\"hello_node_1\", \"hello_node_2\")\n",
        "graph.set_finish_point(\"hello_node_2\") # \"graph.add_edge(hello_node, END)\" also works\n",
        "\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1452a5",
      "metadata": {},
      "source": [
        "Finally, we run it, inputting an initial state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f2bb7426",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello World, Hello <Your Name>'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app.invoke({\"message\": \"World\", \"name\": \"<Your Name>\"})['message']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4898abeb",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üë®‚Äçüíª Demo - Chatbot (Implementing Memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96381a84",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#List, Union used to define structures for memory\n",
        "from typing import TypedDict, List, Union \n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f47e1730",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Follow Along ###\n",
        "\n",
        "# We first define our AgentState\n",
        "class AgentState(TypedDict):\n",
        "    pass\n",
        "\n",
        "# Then our llm object\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# Then our nodes\n",
        "def process(state: AgentState) -> AgentState:\n",
        "    pass\n",
        "\n",
        "\n",
        "# We define our graph\n",
        "\n",
        "\n",
        "# We create a loop for repeating conversation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "591f98dd",
      "metadata": {},
      "source": [
        "### üë®‚Äçüíª Demo - Upgrading the Chatbot and Adding a Weather Tool\n",
        "(Copy/paste the above cell or keep working on the same one)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5415a135",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, Sequence, TypedDict\n",
        "from dotenv import load_dotenv  \n",
        "from langchain_core.messages import BaseMessage # The foundational class for all message types in LangGraph\n",
        "from langchain_core.messages import ToolMessage # Passes data back to LLM after it calls a tool such as the content and the tool_call_id\n",
        "from langchain_core.messages import SystemMessage # Message for providing instructions to the LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edf4ed0",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Follow Along ###\n",
        "\n",
        "# Updating our memory definition\n",
        "class AgentState(TypedDict):\n",
        "    messages: List[Union[HumanMessage, AIMessage]]\n",
        "\n",
        "# Defining tool functions\n",
        "\n",
        "# Binding tools to our llm object\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "# Adding a system message to make it more clear what we expect\n",
        "def process(state: AgentState) -> AgentState:\n",
        "    \"\"\"This node will solve the request you input\"\"\"\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "\n",
        "    state[\"messages\"].append(AIMessage(content=response.content)) \n",
        "    print(f\"\\nAI: {response.content}\")\n",
        "    print(\"CURRENT STATE: \", state[\"messages\"])\n",
        "\n",
        "    #Updating the way we return state - this way actually a new dict, not just modifies it\n",
        "    return state\n",
        "\n",
        "#Adding a conditional function to determine path after \n",
        "\n",
        "\n",
        "# Update our graph to include tool nodes and conditional edges\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"process\", process)\n",
        "graph.add_edge(START, \"process\")\n",
        "graph.add_edge(\"process\", END) \n",
        "agent = graph.compile()\n",
        "\n",
        "\n",
        "#Create a loop for repeating conversation\n",
        "conversation_history = []\n",
        "\n",
        "user_input = input(\"Enter: \")\n",
        "while user_input != \"exit\":\n",
        "    conversation_history.append(HumanMessage(content=user_input))\n",
        "    result = agent.invoke({\"messages\": conversation_history})\n",
        "    conversation_history = result[\"messages\"]\n",
        "    user_input = input(\"Enter: \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d565f81",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üå™Ô∏è Exercise - Create a Whimsical Chatbot with Calculation Tools: (Addition, Subtraction, Multiplication, Division)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa152c7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Use previous resources to help you ##\n",
        "\n",
        "# Define your Agent State\n",
        "class AgentState(TypedDict):\n",
        "    pass\n",
        "\n",
        "#Define all your calculation tools, you have an unfinished example:\n",
        "@tool\n",
        "def add(a: int, b:int):\n",
        "    \"\"\"This is an addition function that adds 2 numbers together\"\"\"\n",
        "    pass\n",
        "\n",
        "#Add all your tools into a list\n",
        "\n",
        "\n",
        "#Create your LLM object - remember to bind tools!\n",
        "\n",
        "\n",
        "#Create your agent node - try to keep good practise methods you learned. Make your chatbot whimsical!!\n",
        "def agent_node(state:AgentState) -> AgentState:\n",
        "    pass\n",
        "\n",
        "#Create your condition node\n",
        "def should_continue(state: AgentState): \n",
        "    pass\n",
        "    \n",
        "#Define your graph and compile it into a variable called 'agent'\n",
        "\n",
        "\n",
        "\n",
        "#The print_stream function is provided for clean serial output\n",
        "def print_stream(stream):\n",
        "    for s in stream:\n",
        "        message = s[\"messages\"][-1]\n",
        "        if isinstance(message, tuple):\n",
        "            print(message)\n",
        "        else:\n",
        "            message.pretty_print()\n",
        "\n",
        "inputs = {\"messages\": [(\"user\", \"Add 40 + 12 and then multiply the result by 6. Then divide by 15. Also tell me a joke please.\")]}\n",
        "print_stream(agent.stream(inputs, stream_mode=\"values\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06ed29c8",
      "metadata": {},
      "source": [
        "### Success Criteria:\n",
        "- Your agent answers prompts in a whimsical manner\n",
        "- Your agent uses tools \n",
        "- Every single one of your tools works correctly\n",
        "- Your agent can use tools and answer different queries from one user message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0916567b",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üß™ LAB: Creating a Multi-Agent Graph \n",
        "\n",
        "Your final task to do in the remainder of this course + during some extra time at the end or back at home. Program a full LangGraph graph implementing LCEL from LangChain to create a multi-agnet system. LCEL is the chaining system in LangChain, it's your turn to research for the next 10 minutes and implement it yourself. After 10 minutes I will post the LCEL nodes themselves - you will still have to graph it.\n",
        "\n",
        "You are creating a two part joke teller, where the first node would tell the set up, and the following would finish off with a punchline. You will do this task without a prior template or direct tutorial, but to balance to difficulty it is a relatively simple task.\n",
        "\n",
        "Throughout this course you have learned how to create most of this. You just have to fit in the LCEL into each node\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b7c86f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.graph import StateGraph, END\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48706046",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define State\n",
        "\n",
        "\n",
        "\n",
        "#Create LLM\n",
        "\n",
        "\n",
        "\n",
        "# Node 1 (Generate Joke Setup)\n",
        "\n",
        "\n",
        "\n",
        "# Node 2 = Generate Punchline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build Graph\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Run the Graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af7895b2",
      "metadata": {},
      "source": [
        "### Success Criteria:\n",
        "- Each cell is making its own LLM call\n",
        "- You are utlising LCEL in your graph\n",
        "- You have one LCEL node writing the joke setup, the other the punchline "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46455ff9",
      "metadata": {},
      "source": [
        "---\n",
        "## üèÅ Conclusion\n",
        "\n",
        "LangGraph provides a powerful way to structure intelligent systems using graph-based workflows.\n",
        "\n",
        "By combining deterministic control with agent-based reasoning, it enables scalable and production-ready AI applications.\n",
        "\n",
        "Through learning graph modeling, tool integration, persistent memory handling, and multi-agent coordination, developers gain the foundation needed to build complex real-world AI systems.\n",
        "\n",
        "**You now have the conceptual foundation needed to begin building LangGraph-powered systems.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Further Learning Areas:\n",
        "- Injectable states in LangGraph\n",
        "- Stateful Iteration & Feedback Loops\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.13.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
